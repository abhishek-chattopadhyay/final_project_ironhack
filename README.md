# ğŸ³ Marine Life Detection  
### A Computer Vision Project Combined With Unsupervised & Transfer Learning | Ironhack Data Science Bootcamp
![](./presentation/marine_life.png)

## ğŸ“Œ Introduction  
This project focuses on building a deep learning pipeline to classify marine animal images into distinct categories using transfer learning with MobileNetV2. The images are preprocessed and stored as `.pt` tensors, grouped by visual similarity through unsupervised learning. 
The model is trained with data augmentation, early stopping, and validation monitoring, achieving robust performance on unseen test images.

To make the model accessible, a Streamlit app is included for drag-and-drop image classification in real-time. The app accepts `.jpg` or `.png` files and returns the predicted class instantly.

The complete workflowâ€”from data handling and training to evaluation and deploymentâ€”is designed to be modular and easy to extend for future datasets or classification tasks.


## ğŸ¯ Project Goals  
- âœ… Preprocess and normalize unlabeled `.pt` image tensors into labeled datasets through unsupervised clustering.
- âœ… Apply data augmentation techniques to improve model generalization.
- âœ… Train a multi-class image classifier using MobileNetV2 with early stopping and model checkpointing.
- âœ… Evaluate model performance using validation metrics and a confusion matrix on the test set.
- âœ… Build an interactive Streamlit web application for real-time image prediction with drag-and-drop support.

## ğŸ“‚ Data Source  
- **Marine Life Images**  
  ğŸ“ [Download here](https://www.kaggle.com/datasets/cyanex1702/oceanic-life-dataset)  
  This dataset consists 7990 unlabelled images of different marine lives.

## âš™ï¸ Methodology  
1. **Data Clustering**:  
   - Used unsupervised machine learning (e.g. K-means clustering) to label the images into different categories.
   - Used DBSCAN to remove the outlier and further fine-tune the labels. 

2. **Model Architecture**:  
   - Used `MobileNetV2` (a lightweight, efficient CNN model) as the backbone for classification.  
   - Applied transfer learning by fine-tuning only the top layers to adapt to our specific classification task.

3. **Training Setup**:  
   - Trained for **30 epochs** with early stopping based on validation loss.  
   - Saved the best performing model as `best_model.pt`.  

4. **Evaluation**:  
   - Assessed model performance using **accuracy**, **loss curves**, and a **confusion matrix**.

## ğŸ’¡ Key Insights  
- `MobileNetV2` achieved a high classification **accuracy of 99%**.  
- The model showed **minimal Type I and Type II errors**, making it highly reliable.  
- Transfer learning significantly improved efficiency and performance, even with a moderately sized dataset.

## ğŸ§¾ Project Structure  
```bash
final_project_ironhack/
â”‚
â”œâ”€â”€ data/                 # Download the images from Kaggle and keep your images here
â”œâ”€â”€ notebooks/            # Jupyter Notebooks for image preprocessing, feature extraction and unsupervised learning, outlier detection, transfer learning using MobileNetV2 and a Streamlit app (app.py)
â”œâ”€â”€ labels/               # labels of the clusters
â”œâ”€â”€ models/               # some models are saved here as .pt format
â”œâ”€â”€ presentation/         # Presentation to the stakeholder 
â”œâ”€â”€ README.md             # Project documentation (this file) 
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸš€ Getting Started
1. Clone the repository
   ```bash
   git clone https://github.com/abhishek-chattopadhyay/project-4-cv.git
   cd project-4-cv
   ```
2. Create a virtual environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```
3. Download the data from the link and put it into the data folder.
4. Run the `.ipynb` files from 01 to 03.

## ğŸ“ Extra Notes
- This project was developed as part of the Ironhack Data Science Bootcamp.
- Future enhancements could include:
  - Trying other models like EfficientNet, ResNet, or ensemble techniques.
  - Expanding the dataset to include more species.
  - Deploying the model via a simple web app for demo purposes.
